{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\"\"\"\n",
    "NiN是 网络中的网络\n",
    "其想法是在每个像素位置(针对每个高度和宽度)应用一个全连接层。\n",
    "如果将权重连接到每个空间位置,可以将其视为1*1卷积层,或作为在每个像素位置上独立作用的全连接层。\n",
    "从另一个角度看，即将空间维度中的每个像素视为单个样本,将通道维度视为不同特征(feature)。\n",
    "\n",
    "NiN使用由一个卷积层和多个1*1卷积层组成的块。该块可以在卷积神经网络中使用,以允许更多的每像素非线性。\n",
    "NiN去除了容易造成过拟合的全连接层,将它们替换为全局平均汇聚层（即在所有位置上进行求和）。\n",
    "该汇聚层通道数量为所需的输出数量(例如,Fashion-MNIST的输出为10)。\n",
    "移除全连接层可减少过拟合,同时显著减少NiN的参数。\n",
    "\"\"\"\n",
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding): # NiN块,先是自定义卷积层,之后过两层1*1卷积层\n",
    "    return nn.Sequential(\n",
    "    nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),\n",
    "    nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())\n",
    "NiN = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "    nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小,10)\n",
    "    nn.Flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
