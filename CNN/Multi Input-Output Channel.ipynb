{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多通道输入的卷积:\n",
      "tensor([[ 56.,  72.],\n",
      "        [104., 120.]])\n",
      "K.shape:torch.Size([3, 2, 2, 2])\n",
      "多通道输出的卷积:\n",
      "tensor([[[ 56.,  72.],\n",
      "         [104., 120.]],\n",
      "\n",
      "        [[ 76., 100.],\n",
      "         [148., 172.]],\n",
      "\n",
      "        [[ 96., 128.],\n",
      "         [192., 224.]]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\"\"\"\n",
    "当添加通道时,输入和隐藏的表示都变成了三维张量。\n",
    "例如,每个RGB输入图像具有3*h*w的形状。\n",
    "将这个大小为3的轴称为通道维度\n",
    "\"\"\"\n",
    "\n",
    "# 一、多输入通道\n",
    "\"\"\"\n",
    "当输入包含多个通道时,需要构造一个与输入数据具有相同输入通道数的卷积核,以便与输入数据进行互相关运算。\n",
    "假设输入的通道数为c,那么卷积核的输入通道数也需要为c。\n",
    "如果卷积核的窗口形状是kh*kw,当c = 1时,可以把卷积核看作形状为 kh*kw 的二维张量\n",
    "\n",
    "当c > 1时,我们卷积核的每个输入通道将包含形状为 kh*kw 的张量。将这些张量 c[i] 连结在一起可以\n",
    "得到形状为 c[i]*kh*kw 的卷积核。由于输入和卷积核都有c个通道,可以对每个通道输入的二维张量和\n",
    "卷积核的二维张量进行互相关运算,再对通道求和(将c[i]的结果相加)得到二维张量。\n",
    "这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果。\n",
    "\"\"\"\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros(X.shape[0]-h+1, X.shape[1]-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "    return Y\n",
    "def corr2d_multi_in(X, K): # 相当于一个输入通道对应一个卷积核,最后将每个通道的卷积结果相加\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "                  [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], \n",
    "                  [[1.0, 2.0], [3.0, 4.0]]])\n",
    "print(f\"多通道输入的卷积:\\n{corr2d_multi_in(X,K)}\")\n",
    "\n",
    "# 二、多输出通道\n",
    "\"\"\"\n",
    "在最流行的神经网络架构中，随着神经网络层数的加深，常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。\n",
    "直观地说，可以将每个通道看作对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。\n",
    "因此，多输出通道并不仅是学习多个单通道的检测器。\n",
    "\n",
    "用ci和co分别表示输入和输出通道的数目,并让kh和kw为卷积核的高度和宽度。为了获得多个通道的输出,\n",
    "可以为每个输出通道创建一个形状为 ci*kh*kw 的卷积核张量,这样卷积核的形状是 co*ci*kh*kw。\n",
    "在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。\n",
    "\"\"\"\n",
    "def corr2d_multi_in_out(X, K): # 计算多个通道的输出的互相关函数\n",
    "    # 迭代K的第0个维度，每次都对输入X执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], dim=0)\n",
    "# 通过将核张量K与K+1(K中每个元素加1)和K+2连接起来，构造了一个具有3个输出通道的卷积核。\n",
    "K = torch.stack((K,K+1,K+2), dim=0)\n",
    "print(f\"K.shape:{K.shape}\")\n",
    "print(f\"多通道输出的卷积:\\n{corr2d_multi_in_out(X,K)}\") # 输出包含三个通道,第一个通道与X和K的多输入通道卷积一致\n",
    "\n",
    "# 三、1*1卷积层\n",
    "\"\"\"\n",
    "1*1卷积层没有提取相邻像素特征关系的能力,\n",
    "可将其看作一个在每个像素位置应用的全连接层,实现从ci个输入值到co个输出值的转换,\n",
    "且权重一致(权重维度 co*ci + 偏置b), 指的是对于每一维的输入,进行变换的权重是一致的,不同维度的权重是不一样的\n",
    "1*1卷积层通常用于调整网络层的通道数量和控制模型复杂性\n",
    "\"\"\"\n",
    "def corr2d_multi_in_out_1x1(X, K): # 注意需要对输入和输出的数据形状进行调整\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h*w)) # 每个通道,二维像素矩阵到一维向量\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))\n",
    "# 1*1的卷积运算相当于实现数corr2d_multi_in_out\n",
    "X = torch.normal(mean=0, std=1, size=(3, 3, 3))\n",
    "K = torch.normal(mean=0, std=1, size=(2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "print(float(torch.abs(Y1 - Y2).sum()) < 1e-6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
