{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "设置卷积核为3*3,padding=(2,2)的Y的形状:torch.Size([8, 8])\n",
      "设置卷积核为5*3,padding=(4,2)的Y的形状:torch.Size([8, 8])\n",
      "设置卷积核为3*3,padding=(2,2),stride=2的Y的形状:torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 一、填充(Padding)\n",
    "\"\"\"\n",
    "在应用多层卷积时,常常丢失边缘像素。由于通常使用小卷积核,因此对于任何单个卷积,\n",
    "可能只会丢失几个像素。但随着应用许多连续卷积层,累积丢失的像素数就多了。\n",
    "解决这个问题的简单方法即为填充:在输入图像的边界填充元素(通常填充元素是0)\n",
    "\n",
    "不使用填充时,输入形状为h*w,卷积核形状为kh*kw,输出形状为 (h-kh+1)*(w-kw+1)\n",
    "使用填充时,如果添加ph行填充(大约一半在顶部,一半在底部)和pw列填充(左侧大约一半,右侧一半),\n",
    "则输出形状将为 (h-kh+ph+1)*(w-kw+pw+1) 即输出的高度和宽度将分别增加ph和pw。\n",
    "\n",
    "在许多情况下,设置 ph = kh - 1和pw = kw - 1 ,使输入和输出具有相同的高度和宽度\n",
    "这样可以在构建网络时更容易地预测每个图层的输出形状\n",
    "\n",
    "卷积神经网络中卷积核的高度和宽度通常为奇数,例如1、3、5或7。\n",
    "选择奇数的好处是,保持空间维度的同时,可以在顶部和底部填充相同数量的行,在左侧和右侧填充相同数量的列\n",
    "\n",
    "此外,使用奇数的核大小和填充大小也提供了书写上的便利。对于任何二维张量X, 当满足:\n",
    "1. 卷积核的大小是奇数\n",
    "2. 所有边的填充行数和列数相同\n",
    "3. 输出与输入具有相同高度和宽度\n",
    "则可以得出:输出Y[i, j]是通过以输入X[i, j]为中心,与卷积核进行互相关计算得到的。\n",
    "\"\"\"\n",
    "# 为了方便起见,我们定义了一个计算卷积层的函数。\n",
    "# 此函数初始化卷积层权重,并对输入和输出提高和缩减相应的维数\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1,1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "# 注意,这里每边都填充了1行或1列,因此总共添加了2行或2列\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8,8))\n",
    "print(f\"设置卷积核为3*3,padding=(2,2)的Y的形状:{comp_conv2d(conv2d, X).shape}\")\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5,3), padding=(2,1)) # 当卷积核的高度和宽度不同时,我们可以填充不同的高度和宽度,使输出和输入具有相同的高度和宽度\n",
    "print(f\"设置卷积核为5*3,padding=(4,2)的Y的形状:{comp_conv2d(conv2d, X).shape}\")\n",
    "\n",
    "# 二、步幅(Stride)\n",
    "\"\"\"\n",
    "在计算互相关时,卷积窗口从输入张量的左上角开始,向下、向右滑动。在前面的例子中,默认每次滑动\n",
    "一个元素。但是,有时候为了高效计算或是缩减采样次数,卷积窗口可以跳过中间位置,每次滑动多个元素。\n",
    "每次滑动的元素数量称为步幅,步幅可以在垂直方向h和水平方向w具有不同的大小\n",
    "\n",
    "垂直步幅为sh,水平步幅为sw时, 输出形状为:\n",
    "floor( (h-kh+ph+sh)/sh ) * ( (w-kw+pw+sw)/sw )\n",
    "如果输入的高度和宽度可以被垂直步幅和水平步幅整除,输出形状为:\n",
    "h/sh * w/sw\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "为了简洁起见,当输入高度和宽度两侧的填充数量分别为ph和pw时,我们称之为填充(ph, pw)。当ph = pw =\n",
    "p时,填充是p。同理,当高度和宽度上的步幅分别为sh和sw时,我们称之为步幅(sh, sw)。特别地,当sh = sw = s时,\n",
    "我们称步幅为s。默认情况下,填充为0,步幅为1。在实践中,我们很少使用不一致的步幅或填充,也就是说,\n",
    "我们通常有ph = pw和sh = sw。\n",
    "\"\"\"\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2) # 将高度和宽度的步幅设置为2,从而将输入的高度和宽度减半\n",
    "print(f\"设置卷积核为3*3,padding=(2,2),stride=2的Y的形状:{comp_conv2d(conv2d, X).shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
